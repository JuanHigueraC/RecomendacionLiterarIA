{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando y buscando hiperparámetros para: LinearRegression\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      " > Mejor score (cv): 0.8773\n",
      " > Mejor combinación de parámetros: {'fit_intercept': False}\n",
      "\n",
      "Entrenando y buscando hiperparámetros para: Ridge\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      " > Mejor score (cv): 0.8778\n",
      " > Mejor combinación de parámetros: {'alpha': 0.1, 'fit_intercept': False}\n",
      "\n",
      "Entrenando y buscando hiperparámetros para: SVR\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      " > Mejor score (cv): 0.8690\n",
      " > Mejor combinación de parámetros: {'C': 100, 'epsilon': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Entrenando y buscando hiperparámetros para: RandomForest\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      " > Mejor score (cv): 0.8481\n",
      " > Mejor combinación de parámetros: {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "\n",
      "Entrenando y buscando hiperparámetros para: KNeighbors\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      " > Mejor score (cv): 0.6637\n",
      " > Mejor combinación de parámetros: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "\n",
      "Entrenando y buscando hiperparámetros para: RANSAC\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      " > Mejor score (cv): 0.8737\n",
      " > Mejor combinación de parámetros: {'max_trials': 50, 'min_samples': 0.5, 'stop_n_inliers': 100}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RANSACRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# ===========================================================\n",
    "# Ejemplo de datos simulados (reemplaza con tus datos reales)\n",
    "# ===========================================================\n",
    "# X: matriz de features (n_muestras, n_features)\n",
    "# y: vector o matriz de objetivos (n_muestras,) o (n_muestras, n_targets)\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(200, 10)\n",
    "y = X[:, 0]*3.5 + X[:, 1]*(-2.4) + 0.5 * np.random.randn(200)\n",
    "\n",
    "# ===========================================================\n",
    "# Definición de los modelos a probar en un diccionario\n",
    "# ===========================================================\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'SVR': SVR(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'KNeighbors': KNeighborsRegressor(),\n",
    "    'RANSAC': RANSACRegressor()\n",
    "}\n",
    "\n",
    "# ===========================================================\n",
    "# Definición de los hiperparámetros a probar (param_grid)\n",
    "# Cada clave debe corresponder con la del diccionario 'models'\n",
    "# ===========================================================\n",
    "param_grids = {\n",
    "    'LinearRegression': {\n",
    "        'fit_intercept': [True, False]\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': [0.1, 1.0, 10.0, 100.0],\n",
    "        'fit_intercept': [True, False]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'epsilon': [0.01, 0.1, 0.5]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_leaf': [1, 2, 5]\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'RANSAC': {\n",
    "        'min_samples': [0.5, 0.75, 1.0],\n",
    "        'max_trials': [50, 100, 200],\n",
    "        'stop_n_inliers': [np.inf, 50, 100]  # Algunas opciones adicionales\n",
    "    }\n",
    "}\n",
    "\n",
    "# ===========================================================\n",
    "# Entrenamiento y búsqueda de hiperparámetros con GridSearchCV\n",
    "# ===========================================================\n",
    "best_estimators = {}\n",
    "best_params = {}\n",
    "best_scores = {}\n",
    "\n",
    "# Dividimos en entrenamiento y test para tener un set aparte (opcional)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEntrenando y buscando hiperparámetros para: {name}\")\n",
    "    \n",
    "    # Definimos el GridSearchCV\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[name],\n",
    "        cv=5,                # Número de folds para cross-validation\n",
    "        scoring='r2',        # Métrica para comparar modelos (R^2)\n",
    "        n_jobs=-1,           # Usa todos los cores disponibles\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Ajustamos el modelo con la búsqueda de grilla\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Guardamos los resultados\n",
    "    best_estimators[name] = grid.best_estimator_\n",
    "    best_params[name] = grid.best_params_\n",
    "    best_scores[name] = grid.best_score_\n",
    "    \n",
    "    print(f\" > Mejor score (cv): {grid.best_score_:.4f}\")\n",
    "    print(f\" > Mejor combinación de parámetros: {grid.best_params_}\")\n",
    "\n",
    "# ===========================================================\n",
    "# Evaluar cada mejor modelo en el set de test (opcional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= Resultados en el test set =======\n",
      "LinearRegression - test R^2: 0.9062\n",
      "Ridge - test R^2: 0.9061\n",
      "SVR - test R^2: 0.9001\n",
      "RandomForest - test R^2: 0.9085\n",
      "KNeighbors - test R^2: 0.7579\n",
      "RANSAC - test R^2: 0.9112\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"\\n======= Resultados en el test set =======\")\n",
    "for name, estimator in best_estimators.items():\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    test_score = r2_score(y_test, y_pred)\n",
    "    print(f\"{name} - test R^2: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAlibros",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
